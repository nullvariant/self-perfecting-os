#!/usr/bin/env python3
"""
æ—¢å­˜noteè¨˜äº‹ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ

ç›®çš„:
    Obsidianç­‰ã«ä¿å­˜ã•ã‚Œã¦ã„ã‚‹æ—¢å­˜ã®noteè¨˜äº‹ã‚’
    nullvariant-writingsã®published/ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«
    ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã€é©åˆ‡ãªãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä»˜ä¸ã™ã‚‹ã€‚

ä½¿ç”¨ä¾‹:
    # å¯¾è©±çš„ã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
    python import_note_articles.py \\
        --source ~/Obsidian/noteè¨˜äº‹/ \\
        --dest ../nullvariant-writings/writings/note/published/

    # ãƒãƒƒãƒå‡¦ç†ï¼ˆmetadata.jsonã‚’ä½¿ç”¨ï¼‰
    python import_note_articles.py \\
        --source ~/Obsidian/noteè¨˜äº‹/ \\
        --dest ../nullvariant-writings/writings/note/published/ \\
        --batch metadata.json

ä¾å­˜é–¢ä¿‚: Pythonæ¨™æº–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã¿
"""

import argparse
import json
import re
import shutil
import yaml
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Optional
import sys


class ArticleImporter:
    """è¨˜äº‹ã‚¤ãƒ³ãƒãƒ¼ãƒˆã®ãƒ¡ã‚¤ãƒ³ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, source_dir: Path, dest_dir: Path, dry_run: bool = False):
        self.source_dir = Path(source_dir)
        self.dest_dir = Path(dest_dir)
        self.dry_run = dry_run
        self.imported = []
        self.skipped = []
        
    def find_markdown_files(self) -> List[Path]:
        """Markdownãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢"""
        markdown_files = []
        
        for pattern in ['*.md', '*.markdown']:
            markdown_files.extend(self.source_dir.glob(pattern))
            # ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚‚æ¤œç´¢
            markdown_files.extend(self.source_dir.glob(f'**/{pattern}'))
        
        # é‡è¤‡é™¤å»ãƒ»ã‚½ãƒ¼ãƒˆ
        unique_files = sorted(set(markdown_files))
        
        print(f"ğŸ“ æ¤œç´¢ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {self.source_dir}")
        print(f"ğŸ“„ è¦‹ã¤ã‹ã£ãŸMarkdownãƒ•ã‚¡ã‚¤ãƒ«: {len(unique_files)}ä»¶")
        
        return unique_files
    
    def extract_title_from_content(self, content: str) -> str:
        """ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã‹ã‚‰ã‚¿ã‚¤ãƒˆãƒ«ã‚’æŠ½å‡º"""
        lines = content.split('\\n')
        for line in lines:
            if line.startswith('# '):
                return line[2:].strip()
        return ""
    
    def guess_date_from_filename(self, file_path: Path) -> Optional[str]:
        """ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰æ—¥ä»˜ã‚’æ¨æ¸¬"""
        # YYYY-MM-DD ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œç´¢
        date_pattern = r'(\\d{4}-\\d{2}-\\d{2})'
        match = re.search(date_pattern, file_path.name)
        if match:
            return match.group(1)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã®æ›´æ–°æ—¥æ™‚ã‚’ä½¿ç”¨
        mtime = datetime.fromtimestamp(file_path.stat().st_mtime)
        return mtime.strftime('%Y-%m-%d')
    
    def extract_note_url_from_content(self, content: str) -> Optional[str]:
        """è¨˜äº‹å†…å®¹ã‹ã‚‰noteã®URLã‚’æŠ½å‡º"""
        # note.comã®URLãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œç´¢
        url_pattern = r'https://note\\.com/[^\\s)]+/n/[a-zA-Z0-9]+'
        match = re.search(url_pattern, content)
        if match:
            return match.group(0)
        return None
    
    def interactive_metadata(self, file_path: Path, content: str) -> Optional[Dict]:
        """å¯¾è©±çš„ã«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å…¥åŠ›"""
        print(f"\\nğŸ“„ ãƒ•ã‚¡ã‚¤ãƒ«: {file_path.name}")
        print("=" * 50)
        
        # ã‚¿ã‚¤ãƒˆãƒ«è‡ªå‹•æŠ½å‡º
        auto_title = self.extract_title_from_content(content)
        if auto_title:
            print(f"ğŸ“ æŠ½å‡ºã•ã‚ŒãŸã‚¿ã‚¤ãƒˆãƒ«: {auto_title}")
            title = input(f"ã‚¿ã‚¤ãƒˆãƒ« [{auto_title}]: ").strip() or auto_title
        else:
            title = input("ã‚¿ã‚¤ãƒˆãƒ« (å¿…é ˆ): ").strip()
            if not title:
                print("âŒ ã‚¿ã‚¤ãƒˆãƒ«ãŒå…¥åŠ›ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                return None
        
        # æ—¥ä»˜
        auto_date = self.guess_date_from_filename(file_path)
        date = input(f"å…¬é–‹æ—¥ (YYYY-MM-DD) [{auto_date}]: ").strip() or auto_date
        
        # URL
        auto_url = self.extract_note_url_from_content(content)
        if auto_url:
            print(f"ğŸ”— æŠ½å‡ºã•ã‚ŒãŸURL: {auto_url}")
            url = input(f"note URL [{auto_url}]: ").strip() or auto_url
        else:
            url = input("note URL (å¿…é ˆ): ").strip()
            if not url:
                print("âŒ URLãŒå…¥åŠ›ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                return None
        
        # ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ 
        platform = input("ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ  [note]: ").strip() or "note"
        
        # ã‚¿ã‚°
        tags_input = input("ã‚¿ã‚° (ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Š): ").strip()
        tags = [tag.strip() for tag in tags_input.split(',')] if tags_input else []
        
        # ç¢ºèª
        print(f"\\nğŸ“‹ è¨­å®šå†…å®¹:")
        print(f"  ã‚¿ã‚¤ãƒˆãƒ«: {title}")
        print(f"  å…¬é–‹æ—¥: {date}")
        print(f"  URL: {url}")
        print(f"  ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ : {platform}")
        print(f"  ã‚¿ã‚°: {tags}")
        
        confirm = input("\\nã“ã®è¨­å®šã§ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¾ã™ã‹ï¼Ÿ [Y/n]: ").strip()
        if confirm.lower() in ['', 'y', 'yes']:
            return {
                'title': title,
                'published_at': date,
                'platform': platform,
                'url': url,
                'canonical_url': url,
                'tags': tags,
                'status': 'published',
                'source_file': file_path.name
            }
        else:
            print("â­ï¸ ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
            return None
    
    def count_words(self, content: str) -> int:
        """æ–‡å­—æ•°ã‚«ã‚¦ãƒ³ãƒˆ"""
        # Front Matteré™¤å»
        content_clean = re.sub(r'^---.*?---\\s*', '', content, flags=re.DOTALL)
        # ç©ºç™½é™¤å»ã—ã¦æ–‡å­—æ•°ã‚«ã‚¦ãƒ³ãƒˆ
        return len(re.sub(r'\\s', '', content_clean))
    
    def generate_frontmatter(self, metadata: Dict, word_count: int) -> str:
        """Front Matterã‚’ç”Ÿæˆ"""
        frontmatter_data = {
            'title': metadata['title'],
            'published_at': metadata['published_at'],
            'platform': metadata['platform'],
            'url': metadata['url'],
            'canonical_url': metadata['canonical_url'],
            'tags': metadata['tags'],
            'status': metadata['status'],
            'word_count': word_count,
            'source_file': metadata['source_file'],
            'imported_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        }
        
        yaml_str = yaml.dump(frontmatter_data, default_flow_style=False, 
                            allow_unicode=True, sort_keys=False)
        return f"---\\n{yaml_str}---\\n\\n"
    
    def generate_dest_filename(self, metadata: Dict) -> str:
        """ã‚¤ãƒ³ãƒãƒ¼ãƒˆå…ˆãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆ"""
        # ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰ã‚¹ãƒ©ãƒƒã‚°ã‚’ç”Ÿæˆ
        title = metadata['title']
        slug = re.sub(r'[^\\w\\s-]', '', title)  # è‹±æ•°å­—ãƒ»ãƒã‚¤ãƒ•ãƒ³ãƒ»ç©ºç™½ã®ã¿
        slug = re.sub(r'\\s+', '-', slug)  # ç©ºç™½ã‚’ãƒã‚¤ãƒ•ãƒ³ã«
        slug = slug.lower().strip('-')
        
        date = metadata['published_at']
        return f"{date}-{slug}.md"
    
    def import_article(self, file_path: Path, metadata: Dict) -> Optional[Path]:
        """è¨˜äº‹ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ"""
        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æ—¢å­˜ã®Front Matteré™¤å»
            content_clean = re.sub(r'^---.*?---\\s*', '', content, flags=re.DOTALL)
            
            # æ–‡å­—æ•°ã‚«ã‚¦ãƒ³ãƒˆ
            word_count = self.count_words(content)
            
            # æ–°ã—ã„Front Matterç”Ÿæˆ
            frontmatter = self.generate_frontmatter(metadata, word_count)
            
            # ã‚¤ãƒ³ãƒãƒ¼ãƒˆå…ˆãƒ•ã‚¡ã‚¤ãƒ«å
            dest_filename = self.generate_dest_filename(metadata)
            dest_path = self.dest_dir / dest_filename
            
            if dest_path.exists():
                if not self.dry_run:
                    response = input(f"ãƒ•ã‚¡ã‚¤ãƒ« {dest_path} ã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™ã€‚ä¸Šæ›¸ãã—ã¾ã™ã‹ï¼Ÿ [y/N]: ")
                    if response.lower() != 'y':
                        print("â­ï¸ ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸã€‚")
                        return None
            
            # æœ€çµ‚ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
            final_content = frontmatter + content_clean
            
            if self.dry_run:
                print(f"[DRY RUN] {file_path} â†’ {dest_path}")
                return dest_path
            
            # ã‚¤ãƒ³ãƒãƒ¼ãƒˆå…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
            self.dest_dir.mkdir(parents=True, exist_ok=True)
            
            # ãƒ•ã‚¡ã‚¤ãƒ«æ›¸ãè¾¼ã¿
            with open(dest_path, 'w', encoding='utf-8') as f:
                f.write(final_content)
            
            print(f"âœ… ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Œäº†: {dest_path}")
            return dest_path
            
        except Exception as e:
            print(f"âŒ ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼ ({file_path}): {e}")
            return None
    
    def load_batch_metadata(self, batch_file: Path) -> Dict[str, Dict]:
        """ãƒãƒƒãƒå‡¦ç†ç”¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
        try:
            with open(batch_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"âŒ ãƒãƒƒãƒãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return {}
    
    def generate_report(self) -> str:
        """ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        report = f"""
ğŸ“Š ã‚¤ãƒ³ãƒãƒ¼ãƒˆçµæœãƒ¬ãƒãƒ¼ãƒˆ

ğŸ“„ å‡¦ç†å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(self.imported) + len(self.skipped)}
âœ… ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ: {len(self.imported)}
â­ï¸ ã‚¹ã‚­ãƒƒãƒ—: {len(self.skipped)}

âœ… ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸã—ãŸãƒ•ã‚¡ã‚¤ãƒ«:
"""
        for file_path in self.imported:
            report += f"  - {file_path}\\n"
        
        if self.skipped:
            report += f"\\nâ­ï¸ ã‚¹ã‚­ãƒƒãƒ—ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«:\\n"
            for file_path in self.skipped:
                report += f"  - {file_path}\\n"
        
        return report
    
    def execute(self, batch_metadata: Optional[Dict[str, Dict]] = None):
        """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
        print(f"ğŸš€ è¨˜äº‹ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’é–‹å§‹...")
        print(f"ğŸ“ ã‚½ãƒ¼ã‚¹: {self.source_dir}")
        print(f"ğŸ“ ã‚¤ãƒ³ãƒãƒ¼ãƒˆå…ˆ: {self.dest_dir}")
        
        if self.dry_run:
            print("ğŸ” [DRY RUN MODE] å®Ÿéš›ã®ãƒ•ã‚¡ã‚¤ãƒ«æ“ä½œã¯è¡Œã„ã¾ã›ã‚“")
        
        markdown_files = self.find_markdown_files()
        
        if not markdown_files:
            print("âŒ Markdownãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            return
        
        for file_path in markdown_files:
            print(f"\\n" + "="*60)
            
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
            except Exception as e:
                print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ ({file_path}): {e}")
                self.skipped.append(file_path)
                continue
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å–å¾—
            if batch_metadata and file_path.name in batch_metadata:
                # ãƒãƒƒãƒå‡¦ç†
                metadata = batch_metadata[file_path.name]
                print(f"ğŸ“„ ãƒãƒƒãƒå‡¦ç†: {file_path.name}")
            else:
                # å¯¾è©±çš„å…¥åŠ›
                metadata = self.interactive_metadata(file_path, content)
            
            if metadata is None:
                self.skipped.append(file_path)
                continue
            
            # ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Ÿè¡Œ
            dest_path = self.import_article(file_path, metadata)
            if dest_path:
                self.imported.append(dest_path)
            else:
                self.skipped.append(file_path)
        
        # ãƒ¬ãƒãƒ¼ãƒˆè¡¨ç¤º
        print("\\n" + "="*60)
        print(self.generate_report())


def main():
    parser = argparse.ArgumentParser(
        description='æ—¢å­˜noteè¨˜äº‹ã‚’nullvariant-writingsã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆ',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ä¾‹:
    # å¯¾è©±çš„ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
    python import_note_articles.py \\
        --source ~/Obsidian/noteè¨˜äº‹/ \\
        --dest ../nullvariant-writings/writings/note/published/

    # ãƒãƒƒãƒå‡¦ç†
    python import_note_articles.py \\
        --source ~/Obsidian/noteè¨˜äº‹/ \\
        --dest ../nullvariant-writings/writings/note/published/ \\
        --batch metadata.json

    # ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³
    python import_note_articles.py \\
        --source ~/Obsidian/noteè¨˜äº‹/ \\
        --dest ../nullvariant-writings/writings/note/published/ \\
        --dry-run
        """)
    
    parser.add_argument('--source', type=Path, required=True, 
                       help='ã‚¤ãƒ³ãƒãƒ¼ãƒˆå…ƒãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª')
    parser.add_argument('--dest', type=Path, required=True, 
                       help='ã‚¤ãƒ³ãƒãƒ¼ãƒˆå…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª')
    parser.add_argument('--batch', type=Path, 
                       help='ãƒãƒƒãƒå‡¦ç†ç”¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿JSONãƒ•ã‚¡ã‚¤ãƒ«')
    parser.add_argument('--dry-run', action='store_true', 
                       help='å®Ÿè¡Œã›ãšã«å‡¦ç†å†…å®¹ã‚’ç¢ºèª')
    
    args = parser.parse_args()
    
    # ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
    if not args.source.exists():
        print(f"âŒ ã‚½ãƒ¼ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {args.source}")
        sys.exit(1)
    
    if not args.source.is_dir():
        print(f"âŒ ã‚½ãƒ¼ã‚¹ã¯ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™: {args.source}")
        sys.exit(1)
    
    # ãƒãƒƒãƒãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    batch_metadata = None
    if args.batch:
        if not args.batch.exists():
            print(f"âŒ ãƒãƒƒãƒãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {args.batch}")
            sys.exit(1)
        importer = ArticleImporter(args.source, args.dest, args.dry_run)
        batch_metadata = importer.load_batch_metadata(args.batch)
    
    # ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Ÿè¡Œ
    importer = ArticleImporter(args.source, args.dest, args.dry_run)
    importer.execute(batch_metadata)


if __name__ == '__main__':
    main()