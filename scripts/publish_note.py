#!/usr/bin/env python3
"""
noteè¨˜äº‹å…¬é–‹å¾Œã®å‡¦ç†ã‚’è‡ªå‹•åŒ–

ç›®çš„:
    noteç­‰ã®ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã«è¨˜äº‹ã‚’å…¬é–‹ã—ãŸå¾Œã€
    ä¸‹æ›¸ããƒ•ã‚¡ã‚¤ãƒ«ã‚’å…¬é–‹æ¸ˆã¿ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã«ç§»å‹•ã—ã€
    ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ã—ã¦ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã™ã‚‹ã€‚

ä½¿ç”¨ä¾‹:
    python publish_note.py \
        ../nullvariant-writings/writings/note/drafts/2025-10-16-topic.md \
        --url https://note.com/nullvariant/n/xxxxx \
        --platform note \
        --date 2025-10-16

ä¾å­˜é–¢ä¿‚: Pythonæ¨™æº–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã¿
"""

import argparse
import shutil
import re
import yaml
from pathlib import Path
from datetime import datetime
from typing import Dict, Optional, List
import sys


class NotePublisher:
    """noteè¨˜äº‹å…¬é–‹å‡¦ç†ã®ãƒ¡ã‚¤ãƒ³ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, draft_path: Path, url: str, platform: str, 
                 publish_date: str, dry_run: bool = False):
        self.draft_path = Path(draft_path)
        self.url = url
        self.platform = platform
        self.publish_date = publish_date
        self.dry_run = dry_run
        
        # ãƒ‘ã‚¹è¨­å®š
        # ../nullvariant-writings/writings/note/drafts/file.md ã‹ã‚‰
        # ../nullvariant-writings ã‚’å–å¾—
        current_path = self.draft_path.parent  # drafts
        current_path = current_path.parent     # note
        current_path = current_path.parent     # writings
        self.writings_root = current_path.parent  # nullvariant-writings
        
        self.published_dir = self.writings_root / "writings" / platform / "published"
        self.corpus_file = self.writings_root / "CORPUS.md"
        
    def extract_title(self, content: str) -> str:
        """Markdownã‹ã‚‰è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«ã‚’æŠ½å‡º"""
        lines = content.split('\n')
        for line in lines:
            if line.startswith('# '):
                return line[2:].strip()
        
        # H1ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰æ¨æ¸¬
        stem = self.draft_path.stem
        # YYYY-MM-DD- ã®ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’é™¤å»
        title_part = re.sub(r'^\d{4}-\d{2}-\d{2}-', '', stem)
        return title_part.replace('-', ' ').title()
    
    def count_words(self, content: str) -> int:
        """æ—¥æœ¬èªã‚’è€ƒæ…®ã—ãŸæ–‡å­—æ•°ã‚«ã‚¦ãƒ³ãƒˆ"""
        # Markdownã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿éƒ¨åˆ†ã‚’é™¤å»
        content_without_frontmatter = re.sub(r'^---.*?---\s*', '', content, flags=re.DOTALL)
        # æ”¹è¡Œãƒ»ç©ºç™½ã‚’é™¤å»ã—ã¦æ–‡å­—æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
        clean_content = re.sub(r'\s', '', content_without_frontmatter)
        return len(clean_content)
    
    def extract_tags(self, content: str) -> List[str]:
        """è¨˜äº‹æœ«å°¾ã®ã‚¿ã‚°ã‚’æŠ½å‡º"""
        # **ã‚¿ã‚°**: #tag1 #tag2 å½¢å¼ã‚’æ¤œç´¢
        tag_pattern = r'\*\*ã‚¿ã‚°\*\*[:\s]*(.+)'
        match = re.search(tag_pattern, content)
        if match:
            tag_text = match.group(1)
            # #ã§å§‹ã¾ã‚‹å˜èªã‚’æŠ½å‡º
            tags = re.findall(r'#(\w+)', tag_text)
            return tags
        return []
    
    def generate_metadata(self, content: str) -> Dict:
        """è¨˜äº‹ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ"""
        title = self.extract_title(content)
        word_count = self.count_words(content)
        tags = self.extract_tags(content)
        
        return {
            'title': title,
            'published_at': self.publish_date,
            'platform': self.platform,
            'url': self.url,
            'canonical_url': self.url,
            'source_draft': self.draft_path.name,
            'tags': tags,
            'status': 'published',
            'word_count': word_count
        }
    
    def generate_frontmatter(self, title: str, word_count: int, tags: List[str]) -> str:
        """Front Matterã‚’ç”Ÿæˆ"""
        frontmatter = {
            'title': title,
            'published_at': self.publish_date,
            'platform': self.platform,
            'url': self.url,
            'canonical_url': self.url,  # SEOæ­£è¦ç‰ˆURL
            'source_draft': self.draft_path.name,
            'tags': tags,
            'status': 'published',
            'word_count': word_count
        }
        
        yaml_str = yaml.dump(frontmatter, default_flow_style=False, 
                            allow_unicode=True, sort_keys=False)
        return f"---\n{yaml_str}---\n\n"
    
    def add_frontmatter(self, content: str) -> str:
        """æ—¢å­˜ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã«Front Matterã‚’è¿½åŠ """
        title = self.extract_title(content)
        word_count = self.count_words(content)
        tags = self.extract_tags(content)
        
        frontmatter = self.generate_frontmatter(title, word_count, tags)
        
        # æ—¢å­˜ã®Front MatterãŒã‚ã‚Œã°é™¤å»
        content_without_frontmatter = re.sub(r'^---.*?---\s*', '', content, flags=re.DOTALL)
        
        return frontmatter + content_without_frontmatter
    
    def generate_published_filename(self) -> str:
        """å…¬é–‹æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆ"""
        # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰ãƒˆãƒ”ãƒƒã‚¯éƒ¨åˆ†ã‚’æŠ½å‡º
        stem = self.draft_path.stem
        topic_part = re.sub(r'^\d{4}-\d{2}-\d{2}-', '', stem)
        return f"{self.publish_date}-{topic_part}.md"
    
    def move_to_published(self) -> Path:
        """drafts/ ã‹ã‚‰ published/ ã¸ç§»å‹•"""
        if not self.draft_path.exists():
            raise FileNotFoundError(f"ä¸‹æ›¸ããƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {self.draft_path}")
        
        # å…¬é–‹æ¸ˆã¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ
        self.published_dir.mkdir(parents=True, exist_ok=True)
        
        # å…¬é–‹æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        published_filename = self.generate_published_filename()
        published_path = self.published_dir / published_filename
        
        if published_path.exists():
            if not self.dry_run:
                response = input(f"ãƒ•ã‚¡ã‚¤ãƒ« {published_path} ã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™ã€‚ä¸Šæ›¸ãã—ã¾ã™ã‹ï¼Ÿ [y/N]: ")
                if response.lower() != 'y':
                    print("å‡¦ç†ã‚’ä¸­æ­¢ã—ã¾ã—ãŸã€‚")
                    sys.exit(1)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã‚’èª­ã¿è¾¼ã¿
        with open(self.draft_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # Front Matterè¿½åŠ 
        content_with_metadata = self.add_frontmatter(content)
        
        if self.dry_run:
            print(f"[DRY RUN] {self.draft_path} â†’ {published_path}")
            print(f"[DRY RUN] Front Matter:")
            frontmatter_only = content_with_metadata.split('---\n\n')[0] + '---'
            print(frontmatter_only)
            return published_path
        
        # å…¬é–‹æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã¿
        with open(published_path, 'w', encoding='utf-8') as f:
            f.write(content_with_metadata)
        
        print(f"âœ… å…¬é–‹æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ: {published_path}")
        return published_path
    
    def update_corpus(self, published_path: Path, metadata: Dict):
        """CORPUS.mdã‚’æ›´æ–°"""
        if not self.corpus_file.exists():
            print(f"âš ï¸ CORPUS.mdãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {self.corpus_file}")
            return
        
        if self.dry_run:
            print(f"[DRY RUN] CORPUS.mdæ›´æ–°ã‚’ã‚¹ã‚­ãƒƒãƒ—")
            return
        
        # CORPUS.mdã‚’èª­ã¿è¾¼ã¿
        with open(self.corpus_file, 'r', encoding='utf-8') as f:
            corpus_content = f.read()
        
        # è¨˜äº‹æƒ…å ±ã‚’è¿½åŠ 
        year_month = metadata['published_at'][:7]  # 2025-10
        year, month = year_month.split('-')
        section_header = f"#### {year}å¹´{int(month)}æœˆ"
        
        article_entry = (
            f"- **[{metadata['title']}]({metadata['url']})** "
            f"({metadata['published_at']}) - {metadata['word_count']}æ–‡å­—\n"
            f"  - ã‚¿ã‚°: {', '.join(metadata['tags'])}\n"
        )
        
        # ã‚»ã‚¯ã‚·ãƒ§ãƒ³ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèªã—ã€é©åˆ‡ãªä½ç½®ã«æŒ¿å…¥
        if section_header in corpus_content:
            # æ—¢å­˜ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«è¿½åŠ 
            pattern = f"({re.escape(section_header)}.*?)\n\n"
            match = re.search(pattern, corpus_content, re.DOTALL)
            if match:
                section_content = match.group(1)
                new_section = section_content + "\n" + article_entry
                corpus_content = corpus_content.replace(section_content, new_section)
        else:
            # æ–°ã—ã„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ä½œæˆ
            note_section_start = corpus_content.find("### noteè¨˜äº‹")
            if note_section_start != -1:
                # noteè¨˜äº‹ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®ç›´å¾Œã«æŒ¿å…¥
                insertion_point = corpus_content.find("\n", note_section_start) + 1
                new_section = f"\n{section_header}ï¼ˆ1ä»¶ï¼‰\n\n{article_entry}\n"
                corpus_content = corpus_content[:insertion_point] + new_section + corpus_content[insertion_point:]
        
        # çµ±è¨ˆæƒ…å ±ã®æ›´æ–°
        # ç·è¨˜äº‹æ•°ã¨ç·æ–‡å­—æ•°ã®æ›´æ–°ï¼ˆç°¡æ˜“å®Ÿè£…ï¼‰
        corpus_content = re.sub(
            r'ç·è¨˜äº‹æ•°: \d+',
            f'ç·è¨˜äº‹æ•°: {corpus_content.count("- **[")}"',
            corpus_content
        )
        
        # æœ€çµ‚æ›´æ–°æ—¥ã®æ›´æ–°
        today = datetime.now().strftime('%Y-%m-%d')
        corpus_content = re.sub(
            r'æœ€çµ‚æ›´æ–°: \d{4}-\d{2}-\d{2}',
            f'æœ€çµ‚æ›´æ–°: {today}',
            corpus_content
        )
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãæˆ»ã—
        with open(self.corpus_file, 'w', encoding='utf-8') as f:
            f.write(corpus_content)
        
        print(f"ğŸ“š CORPUS.mdæ›´æ–°: {published_path.name}")
    
    def cleanup_draft(self):
        """ä¸‹æ›¸ããƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤ç¢ºèª"""
        if self.dry_run:
            print(f"[DRY RUN] ä¸‹æ›¸ããƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ã‚’ã‚¹ã‚­ãƒƒãƒ—: {self.draft_path}")
            return
        
        response = input(f"ä¸‹æ›¸ããƒ•ã‚¡ã‚¤ãƒ« {self.draft_path} ã‚’å‰Šé™¤ã—ã¾ã™ã‹ï¼Ÿ [y/N]: ")
        if response.lower() == 'y':
            self.draft_path.unlink()
            print(f"ğŸ—‘ï¸ ä¸‹æ›¸ããƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤: {self.draft_path}")
        else:
            print(f"ğŸ“ ä¸‹æ›¸ããƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿æŒ: {self.draft_path}")
    
    def execute(self) -> bool:
        """ãƒ¡ã‚¤ãƒ³å‡¦ç†å®Ÿè¡Œ"""
        try:
            print(f"ğŸš€ noteè¨˜äº‹å…¬é–‹å‡¦ç†ã‚’é–‹å§‹...")
            print(f"ğŸ“„ ä¸‹æ›¸ã: {self.draft_path}")
            print(f"ğŸŒ URL: {self.url}")
            print(f"ğŸ“… å…¬é–‹æ—¥: {self.publish_date}")
            
            if self.dry_run:
                print("ğŸ” [DRY RUN MODE] å®Ÿéš›ã®å‡¦ç†ã¯è¡Œã„ã¾ã›ã‚“")
            
            # 1. published/ ã¸ç§»å‹•ãƒ»ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿è¿½åŠ 
            published_path = self.move_to_published()
            
            # 2. CORPUS.mdæ›´æ–°
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å†ç”Ÿæˆ
            content = self.draft_path.read_text(encoding='utf-8')
            metadata = self.generate_metadata(content)
            self.update_corpus(published_path, metadata)
            
            # 3. ä¸‹æ›¸ããƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤ç¢ºèª
            if not self.dry_run:
                self.cleanup_draft()
            
            print("âœ… å‡¦ç†å®Œäº†!")
            return True
            
        except Exception as e:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            if self.dry_run:
                print("ğŸ” [DRY RUN] ã‚¨ãƒ©ãƒ¼ã‚’ç„¡è¦–ã—ã¦ç¶šè¡Œ")
                return True
            return False


def validate_url(url: str) -> bool:
    """URLã®åŸºæœ¬çš„ãªãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³"""
    if not url.startswith(('http://', 'https://')):
        return False
    if 'note.com' in url and '/n/' not in url:
        return False
    return True


def main():
    parser = argparse.ArgumentParser(
        description='noteè¨˜äº‹å…¬é–‹å¾Œã®å‡¦ç†ã‚’è‡ªå‹•åŒ–',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ä¾‹:
    python publish_note.py \\
        ../nullvariant-writings/writings/note/drafts/2025-10-16-topic.md \\
        --url https://note.com/nullvariant/n/xxxxx \\
        --platform note \\
        --date 2025-10-16

    # ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³ï¼ˆå®Ÿéš›ã®å‡¦ç†ã¯è¡Œã‚ãªã„ï¼‰
    python publish_note.py \\
        draft.md --url https://example.com --dry-run
        """)
    
    parser.add_argument('draft', type=Path, help='ä¸‹æ›¸ããƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹')
    parser.add_argument('--url', required=True, help='å…¬é–‹URL')
    parser.add_argument('--platform', default='note', 
                       choices=['note', 'zenn', 'medium'], 
                       help='å…¬é–‹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ  (default: note)')
    parser.add_argument('--date', help='å…¬é–‹æ—¥ï¼ˆYYYY-MM-DDå½¢å¼ã€æœªæŒ‡å®šæ™‚ã¯ä»Šæ—¥ï¼‰')
    parser.add_argument('--dry-run', action='store_true', 
                       help='å®Ÿè¡Œã›ãšã«å‡¦ç†å†…å®¹ã‚’ç¢ºèª')
    
    args = parser.parse_args()
    
    # ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
    if not args.draft.exists():
        print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {args.draft}")
        sys.exit(1)
    
    if not validate_url(args.url):
        print(f"âŒ ç„¡åŠ¹ãªURLã§ã™: {args.url}")
        sys.exit(1)
    
    # å…¬é–‹æ—¥è¨­å®š
    publish_date = args.date or datetime.now().strftime('%Y-%m-%d')
    
    # å‡¦ç†å®Ÿè¡Œ
    publisher = NotePublisher(
        draft_path=args.draft,
        url=args.url,
        platform=args.platform,
        publish_date=publish_date,
        dry_run=args.dry_run
    )
    
    success = publisher.execute()
    sys.exit(0 if success else 1)


if __name__ == '__main__':
    main()